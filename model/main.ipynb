{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/john_gold/Desktop/assigmnt_final/SQuAD_Azerbaijan/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "import torch\n",
    "# from torchtext.datasets import multi30k, Multi30k\n",
    "from typing import Iterable, List\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics.text import BLEUScore\n",
    "from transformers.optimization import AdamW\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import torchmetrics\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('experiments_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/xlm-roberta-large-squad2 were not used when initializing XLMRobertaForQuestionAnswering: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
    "\n",
    "model_name = \"deepset/xlm-roberta-large-squad2\"\n",
    "\n",
    "\n",
    "# nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)\n",
    "# QA_input = {\n",
    "#     'question': 'Beyons neçə yaşında LaTavia Robertsonla tanış oldu?',\n",
    "#     'context': \"\"\"Səkkiz yaşında, Beyonce və uşaqlıq dostu Kelly Rowland, bütün qızlardan ibarət əyləncə qrupunun dinləmələrində LaTavia Roberson ilə tanış oldular. Onlar Girl's Tyme kimi daha üç qızla bir qrupa yerləşdirildilər və Hyustondakı istedad şousunda rap etdi və rəqs etdilər. Qrupu gördükdən sonra R&B prodüseri Arne Frager onları Şimali Kaliforniya studiyasına gətirdi və o zamanlar milli televiziyada ən böyük istedad şousu olan Star Search-ə yerləşdirdi. Girl's Tyme qalib gələ bilmədi və Beyonce daha sonra ifa etdikləri mahnının yaxşı olmadığını söylədi. 1995-ci ildə Beyonsun atası qrupu idarə etmək üçün işindən istefa verdi. Bu addım Beyons ailəsinin gəlirini yarıbayarı azaltdı və valideynləri ayrı mənzillərə köçmək məcburiyyətində qaldılar. Mathew orijinal heyəti dördə kəsdi və qrup digər qurulmuş R&B qız qrupları üçün açılış aktı kimi çıxış etməyə davam etdi. Qızlar səsyazma şirkətlərindən əvvəl dinləmələrdən keçdilər və nəhayət, Elektra Records ilə müqavilə imzaladılar, ilk səsyazmaları üzərində işləmək üçün qısa müddətə Atlanta Records-a köçdülər, ancaq şirkət tərəfindən kəsildi. Bu, ailəni daha da gərginləşdirdi və Beyonsun valideynləri ayrıldı. 5 oktyabr 1995-ci ildə Dwayne Wiggins-in Grass Roots Entertainment qrupu ilə müqavilə imzaladı. 1996-cı ildə qızlar Sony Music ilə razılaşma əsasında debüt albomlarını yazmağa başladılar, Knowles ailəsi yenidən birləşdi və qısa müddət sonra qrup Columbia Records ilə müqavilə bağladı.\t\n",
    "# \"\"\"\n",
    "# }\n",
    "# res = nlp(QA_input)\n",
    "\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('mps')\n",
    "print(device)\n",
    "model = model.to(device)\n",
    "# tokenizer = tokenizer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaForQuestionAnswering(\n",
       "  (roberta): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 1024, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask'])\n",
      "Question: \"19-cu əsrdə \"Karmen\" operasını hansı fransız bəstəkarı yazmışdır?\n",
      "Answer: Georges Bizetin\n",
      "\n",
      "Score: [0.99064815]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import torch\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "# model = AutoModelForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "\n",
    "questions = [\n",
    "    \"\"\"\"19-cu əsrdə \"Karmen\" operasını hansı fransız bəstəkarı yazmışdır?\"\"\"]\n",
    "\n",
    "text = r\"\"\"Qalan qrup üzvləri 2000-ci ildə çəkilmiş Charlie's Angels filminin soundtrackində görünən \"Müstəqil Qadınlar Part I\" mahnısını yazdılar. Ardıcıl on bir həftə ərzində ABŞ-ın Billboard Hot 100 cədvəlində birinci yeri tutaraq, onların ən yaxşı chart olan sinqlı oldu. 2001-ci ilin əvvəlində, Destiny's Child üçüncü albomunu tamamlayarkən, Beyonce amerikalı aktyor Mekhi Phifer ilə birlikdə MTV-nin televiziya üçün hazırlanmış \"Carmen: A Hip Hopera\" filmində böyük rol aldı. Filadelfiyada cərəyan edən film fransız bəstəkarı Georges Bizetin 19-cu əsrdə “Karmen” operasının müasir şərhidir. 2001-ci ilin may ayında üçüncü \"Survivor\" albomu çıxanda Luckett və Roberson mahnıların onlara yönəldiyini iddia edərək məhkəməyə müraciət etdilər. Albom ilk həftədə 663.000 nüsxə satışı ilə ABŞ Billboard 200-də bir nömrədə debüt etdi. Albom digər bir nömrəli hitləri, \"Bootylicious\" və baş treki olan \"Survivor\"u doğurdu, sonuncusu qrupa Duo və ya Vokallı Qrup tərəfindən Ən Yaxşı R&B Performansı üçün Qremmi Mükafatı qazandırdı. 2001-ci ilin oktyabrında 8 Days of Christmas adlı bayram albomunu buraxdıqdan sonra qrup solo karyeralarını davam etdirmək üçün fasilə elan etdi.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "for question in questions:\n",
    "    inputs = tokenizer.encode_plus(question, text, add_special_tokens=True, return_tensors=\"pt\").to(\"mps\")\n",
    "    input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "\n",
    "    text_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    print(inputs.keys())\n",
    "    res = model(**inputs)\n",
    "   \n",
    "    answer_start = torch.argmax(\n",
    "        res['start_logits'])\n",
    "      # Get the most likely beginning of answer with the argmax of the score\n",
    "    answer_end = torch.argmax(res['end_logits']) + 1  # Get the most likely end of answer with the argmax of the score\n",
    "    start = F.softmax(res['start_logits'], dim=1)\n",
    "    end = F.softmax(res['end_logits'], dim=1)\n",
    "\n",
    "    start_index = torch.argmax((start), dim=1)\n",
    "    end_index = torch.argmax((end), dim=1)\n",
    "    \n",
    "    outer = np.matmul(np.expand_dims(start.cpu().detach().numpy(), -1), np.expand_dims(end.cpu().detach().numpy(), 1))\n",
    "    max_answer_len = 512\n",
    "    candidates = np.tril(np.triu(outer), max_answer_len - 1)\n",
    "    idx_sorts = [np.argmax(candidates[i].flatten()) for i in range(len(candidates))]\n",
    "    scores = [candidates[[i], start_index[i], end_index[i]][0] for i in range(len(candidates))]\n",
    "    \n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
    "\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {answer}\\n\")\n",
    "    print(f\"Score: {scores}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('vrashad/squad_azerbaijan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(dataset['train'],columns=dataset['train'].features)\n",
    "df_test = pd.DataFrame(dataset['test'],columns=dataset['test'].features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.dropna()\n",
    "df_test = df_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>is_impossible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56ddde6b9a695914005b9628</td>\n",
       "      <td>Normans</td>\n",
       "      <td>Normanlar (Normand: Nourmands; fransızca: Norm...</td>\n",
       "      <td>Normandiya hansı ölkədə yerləşir?</td>\n",
       "      <td>Fransa</td>\n",
       "      <td>159.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56ddde6b9a695914005b9628</td>\n",
       "      <td>Normans</td>\n",
       "      <td>Normanlar (Normand: Nourmands; fransızca: Norm...</td>\n",
       "      <td>Normandiya hansı ölkədə yerləşir?</td>\n",
       "      <td>Fransa</td>\n",
       "      <td>159.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56ddde6b9a695914005b9628</td>\n",
       "      <td>Normans</td>\n",
       "      <td>Normanlar (Normand: Nourmands; fransızca: Norm...</td>\n",
       "      <td>Normandiya hansı ölkədə yerləşir?</td>\n",
       "      <td>Fransa</td>\n",
       "      <td>159.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56ddde6b9a695914005b9628</td>\n",
       "      <td>Normans</td>\n",
       "      <td>Normanlar (Normand: Nourmands; fransızca: Norm...</td>\n",
       "      <td>Normandiya hansı ölkədə yerləşir?</td>\n",
       "      <td>Fransa</td>\n",
       "      <td>159.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56ddde6b9a695914005b9629</td>\n",
       "      <td>Normans</td>\n",
       "      <td>Normanlar (Normand: Nourmands; fransızca: Norm...</td>\n",
       "      <td>Normandlar nə vaxt Normandiyada idilər?</td>\n",
       "      <td>10 və 11-ci əsrlər</td>\n",
       "      <td>94.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id    title  \\\n",
       "0  56ddde6b9a695914005b9628  Normans   \n",
       "1  56ddde6b9a695914005b9628  Normans   \n",
       "2  56ddde6b9a695914005b9628  Normans   \n",
       "3  56ddde6b9a695914005b9628  Normans   \n",
       "4  56ddde6b9a695914005b9629  Normans   \n",
       "\n",
       "                                             context  \\\n",
       "0  Normanlar (Normand: Nourmands; fransızca: Norm...   \n",
       "1  Normanlar (Normand: Nourmands; fransızca: Norm...   \n",
       "2  Normanlar (Normand: Nourmands; fransızca: Norm...   \n",
       "3  Normanlar (Normand: Nourmands; fransızca: Norm...   \n",
       "4  Normanlar (Normand: Nourmands; fransızca: Norm...   \n",
       "\n",
       "                                  question         answer_text  answer_start  \\\n",
       "0        Normandiya hansı ölkədə yerləşir?              Fransa         159.0   \n",
       "1        Normandiya hansı ölkədə yerləşir?              Fransa         159.0   \n",
       "2        Normandiya hansı ölkədə yerləşir?              Fransa         159.0   \n",
       "3        Normandiya hansı ölkədə yerləşir?              Fransa         159.0   \n",
       "4  Normandlar nə vaxt Normandiyada idilər?  10 və 11-ci əsrlər          94.0   \n",
       "\n",
       "   is_impossible  \n",
       "0          False  \n",
       "1          False  \n",
       "2          False  \n",
       "3          False  \n",
       "4          False  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1572 [01:41<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_index_of_word_in_sentence(context,answer,answer_start):\n",
    "    if answer is not None:\n",
    "        word = answer.split()[0].lower()\n",
    "        try:\n",
    "            answer_start_new = context.lower().index(word)\n",
    "            return {'answer_start':[int(answer_start_new)],'text':[answer]}\n",
    "        except:\n",
    "            return {'answer_start':[int(answer_start)],'text':[answer]}\n",
    "    else:\n",
    "        return {'answer_start':[],'text':[]}\n",
    "\n",
    "df_train['answers']= df_train.apply(lambda x: get_index_of_word_in_sentence(x.context,x.answer_text,x.answer_start),axis=1)\n",
    "df_train.drop(columns=['answer_text','answer_start'],inplace=True)\n",
    "\n",
    "df_test['answers']= df_test.apply(lambda x: get_index_of_word_in_sentence(x.context,x.answer_text,x.answer_start),axis=1)\n",
    "df_test.drop(columns=['answer_text','answer_start'],inplace=True)\n",
    "# df['answers']= df.apply(lambda x: print(x.question),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>is_impossible</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56be85543aeaaa14008c9063</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyonce Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>Beyonce nə vaxt populyarlaşmağa başladı?</td>\n",
       "      <td>False</td>\n",
       "      <td>{'answer_start': [247], 'text': ['1990-cı illə...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56be85543aeaaa14008c9065</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyonce Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>Beyons böyüyərkən hansı sahələrdə yarışırdı?</td>\n",
       "      <td>False</td>\n",
       "      <td>{'answer_start': [203], 'text': ['mahnı oxumaq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56be85543aeaaa14008c9066</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyonce Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>Beyonce nə vaxt Destiny's Child-dən ayrılaraq ...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'answer_start': [534], 'text': ['2003']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56bf6b0f3aeaaa14008c9601</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyonce Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>Beyons hansı şəhərdə və əyalətdə böyüdü?</td>\n",
       "      <td>False</td>\n",
       "      <td>{'answer_start': [166], 'text': ['Hyuston, Tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56bf6b0f3aeaaa14008c9602</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyonce Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>Beyons hansı onillikdə məşhurlaşdı?</td>\n",
       "      <td>False</td>\n",
       "      <td>{'answer_start': [247], 'text': ['1990-cı illə...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130046</th>\n",
       "      <td>5735d259012e2f140011a09d</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>Katmandu Böyükşəhər Şəhəri (KMC), beynəlxalq ə...</td>\n",
       "      <td>Katmandu ilk dəfə ABŞ-ın hansı ştatında beynəl...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'answer_start': [173], 'text': ['Oreqon']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130047</th>\n",
       "      <td>5735d259012e2f140011a09e</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>Katmandu Böyükşəhər Şəhəri (KMC), beynəlxalq ə...</td>\n",
       "      <td>Yanqon əvvəllər nə kimi tanınırdı?</td>\n",
       "      <td>False</td>\n",
       "      <td>{'answer_start': [292], 'text': ['Ranqun']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130048</th>\n",
       "      <td>5735d259012e2f140011a09f</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>Katmandu Böyükşəhər Şəhəri (KMC), beynəlxalq ə...</td>\n",
       "      <td>Katmandunun Belarusun hansı şəhəri ilə əlaqəsi...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'answer_start': [342], 'text': ['Minsk']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130049</th>\n",
       "      <td>5735d259012e2f140011a0a0</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>Katmandu Böyükşəhər Şəhəri (KMC), beynəlxalq ə...</td>\n",
       "      <td>Katmandu ilk beynəlxalq əlaqələri neçənci ildə...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'answer_start': [153], 'text': ['1975']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130050</th>\n",
       "      <td>5735d259012e2f140011a0a1</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>Katmandu Böyükşəhər Şəhəri (KMC), beynəlxalq ə...</td>\n",
       "      <td>KMC nəyin inisializmidir?</td>\n",
       "      <td>False</td>\n",
       "      <td>{'answer_start': [0], 'text': ['Katmandu Böyük...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86820 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id      title  \\\n",
       "0       56be85543aeaaa14008c9063    Beyoncé   \n",
       "1       56be85543aeaaa14008c9065    Beyoncé   \n",
       "2       56be85543aeaaa14008c9066    Beyoncé   \n",
       "3       56bf6b0f3aeaaa14008c9601    Beyoncé   \n",
       "4       56bf6b0f3aeaaa14008c9602    Beyoncé   \n",
       "...                          ...        ...   \n",
       "130046  5735d259012e2f140011a09d  Kathmandu   \n",
       "130047  5735d259012e2f140011a09e  Kathmandu   \n",
       "130048  5735d259012e2f140011a09f  Kathmandu   \n",
       "130049  5735d259012e2f140011a0a0  Kathmandu   \n",
       "130050  5735d259012e2f140011a0a1  Kathmandu   \n",
       "\n",
       "                                                  context  \\\n",
       "0       Beyonce Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "1       Beyonce Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "2       Beyonce Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "3       Beyonce Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "4       Beyonce Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "...                                                   ...   \n",
       "130046  Katmandu Böyükşəhər Şəhəri (KMC), beynəlxalq ə...   \n",
       "130047  Katmandu Böyükşəhər Şəhəri (KMC), beynəlxalq ə...   \n",
       "130048  Katmandu Böyükşəhər Şəhəri (KMC), beynəlxalq ə...   \n",
       "130049  Katmandu Böyükşəhər Şəhəri (KMC), beynəlxalq ə...   \n",
       "130050  Katmandu Böyükşəhər Şəhəri (KMC), beynəlxalq ə...   \n",
       "\n",
       "                                                 question  is_impossible  \\\n",
       "0                Beyonce nə vaxt populyarlaşmağa başladı?          False   \n",
       "1            Beyons böyüyərkən hansı sahələrdə yarışırdı?          False   \n",
       "2       Beyonce nə vaxt Destiny's Child-dən ayrılaraq ...          False   \n",
       "3                Beyons hansı şəhərdə və əyalətdə böyüdü?          False   \n",
       "4                     Beyons hansı onillikdə məşhurlaşdı?          False   \n",
       "...                                                   ...            ...   \n",
       "130046  Katmandu ilk dəfə ABŞ-ın hansı ştatında beynəl...          False   \n",
       "130047                 Yanqon əvvəllər nə kimi tanınırdı?          False   \n",
       "130048  Katmandunun Belarusun hansı şəhəri ilə əlaqəsi...          False   \n",
       "130049  Katmandu ilk beynəlxalq əlaqələri neçənci ildə...          False   \n",
       "130050                          KMC nəyin inisializmidir?          False   \n",
       "\n",
       "                                                  answers  \n",
       "0       {'answer_start': [247], 'text': ['1990-cı illə...  \n",
       "1       {'answer_start': [203], 'text': ['mahnı oxumaq...  \n",
       "2               {'answer_start': [534], 'text': ['2003']}  \n",
       "3       {'answer_start': [166], 'text': ['Hyuston, Tex...  \n",
       "4       {'answer_start': [247], 'text': ['1990-cı illə...  \n",
       "...                                                   ...  \n",
       "130046        {'answer_start': [173], 'text': ['Oreqon']}  \n",
       "130047        {'answer_start': [292], 'text': ['Ranqun']}  \n",
       "130048         {'answer_start': [342], 'text': ['Minsk']}  \n",
       "130049          {'answer_start': [153], 'text': ['1975']}  \n",
       "130050  {'answer_start': [0], 'text': ['Katmandu Böyük...  \n",
       "\n",
       "[86820 rows x 6 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_n = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(df_train),\n",
    "    \"test\": Dataset.from_pandas(df_test)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'is_impossible', 'answers', '__index_level_0__'],\n",
       "        num_rows: 86820\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'is_impossible', 'answers', '__index_level_0__'],\n",
       "        num_rows: 20302\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "max_length = 512 \n",
    "doc_stride = 56\n",
    "pad_on_right = tokenizer.padding_side == \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_features(examples):\n",
    "    # Some of the questions have lots of whitespace on the left, which is not useful and will make the\n",
    "    # truncation of the context fail (the tokenized question will take a lots of space). So we remove that\n",
    "    # left whitespace\n",
    "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
    "\n",
    "    # Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\n",
    "    # in one example possible giving several features when a context is long, each of those features having a\n",
    "    # context that overlaps a bit the context of the previous feature.\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\" if pad_on_right else \"context\"],\n",
    "        examples[\"context\" if pad_on_right else \"question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    " \n",
    "\n",
    "\n",
    "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
    "    # its corresponding example. This key gives us just that.\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "    # The offset mappings will give us a map from token to character position in the original context. This will\n",
    "    # help us compute the start_positions and end_positions.\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "\n",
    "    # Let's label those examples!\n",
    "    tokenized_examples[\"start_positions\"] = []\n",
    "    tokenized_examples[\"end_positions\"] = []\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        # We will label impossible answers with the index of the CLS token.\n",
    "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "\n",
    "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "\n",
    "        # One example can give several spans, this is the index of the example containing this span of text.\n",
    "        sample_index = sample_mapping[i]\n",
    "        answers = examples[\"answers\"][sample_index]\n",
    "        # If no answers are given, set the cls_index as answer.\n",
    "        if len(answers[\"answer_start\"]) == 0:\n",
    "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "        else:\n",
    "            # Start/end character index of the answer in the text.\n",
    "            start_char = answers[\"answer_start\"][0]\n",
    "            end_char = start_char + len(answers[\"text\"][0])\n",
    "\n",
    "            # Start token index of the current span in the text.\n",
    "            token_start_index = 0\n",
    "            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n",
    "                token_start_index += 1\n",
    "\n",
    "            # End token index of the current span in the text.\n",
    "            token_end_index = len(input_ids) - 1\n",
    "            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n",
    "                token_end_index -= 1\n",
    "\n",
    "            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
    "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "            else:\n",
    "                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n",
    "                # Note: we could go after the last offset if the answer is the last word (edge case).\n",
    "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "                    token_start_index += 1\n",
    "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
    "                while offsets[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>is_impossible</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5727746d708984140094de08</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>1200-cü ilə qədər İsveçrə yaylası Savoy, Zähri...</td>\n",
       "      <td>1264-cü ildə Kiburq sülaləsinin süqutuna səbəb...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'answer_start': [294], 'text': ['1263-cü ildə...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>571098c9a58dae1900cd6aaa</td>\n",
       "      <td>Age_of_Enlightenment</td>\n",
       "      <td>Qəhvəxanalar Maarifçilik dövründə biliyin yayı...</td>\n",
       "      <td>Hansı məkan müxtəlif təbəqələrdən olan insanla...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'answer_start': [0], 'text': ['Qəhvəxanalar']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56cef84faab44d1400b88d56</td>\n",
       "      <td>New_York_City</td>\n",
       "      <td>Şəhərin ümumi sahəsi 468,9 kvadrat mil (1,214 ...</td>\n",
       "      <td>Nyu Yorkun ən hündür nöqtəsinin adı nədir?</td>\n",
       "      <td>False</td>\n",
       "      <td>{'answer_start': [175], 'text': ['Todt Hill']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57315c6c497a881900248e82</td>\n",
       "      <td>Mosaic</td>\n",
       "      <td>Konstantin Monomaxosun digər böyük işi 1042-10...</td>\n",
       "      <td>Rus abbat Daniel 1106-07-ci illərdə hara səyah...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'answer_start': [270], 'text': ['Yerusəlim']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570d4d9efed7b91900d45e50</td>\n",
       "      <td>Valencia</td>\n",
       "      <td>15-ci əsrdə günbəz əlavə edildi və neflər xoru...</td>\n",
       "      <td>Həvarilərin qapısı hansı üslubdadır?</td>\n",
       "      <td>False</td>\n",
       "      <td>{'answer_start': [411], 'text': ['Qotika']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9867</th>\n",
       "      <td>56bfb8dca10cfb140055127b</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>O, Destiny's Child ilə yazılan mahnıların əksə...</td>\n",
       "      <td>Jay Z ilə onun yeni mövzuları nələr idi?</td>\n",
       "      <td>False</td>\n",
       "      <td>{'answer_start': [309], 'text': ['insana qullu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9868</th>\n",
       "      <td>57301e6bb2c2fd14005688bd</td>\n",
       "      <td>Roman_Republic</td>\n",
       "      <td>Klodius şəhəri dəhşətə gətirən silahlı dəstələ...</td>\n",
       "      <td>Pompey ardıcıllarına edilən hücumlara kim cava...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'answer_start': [0], 'text': ['Clodius']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9869</th>\n",
       "      <td>56db76b7e7c41114004b5154</td>\n",
       "      <td>2008_Summer_Olympics_torch_relay</td>\n",
       "      <td>Xinhua və CCTV, əksər Qərb mediasından daha ço...</td>\n",
       "      <td>Hansı nəşr etirazçıların insan haqlarını tapda...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'answer_start': [592], 'text': ['Sinxua']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9870</th>\n",
       "      <td>5728cdc64b864d1900164e75</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>Bölgənin bir çox görkəmli muzeyləri Ueyn Dövlə...</td>\n",
       "      <td>MOCAD nə deməkdir?</td>\n",
       "      <td>False</td>\n",
       "      <td>{'answer_start': [171], 'text': ['Detroit Müas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9871</th>\n",
       "      <td>570aae5d4103511400d59920</td>\n",
       "      <td>Aircraft_carrier</td>\n",
       "      <td>Görülə bilən başqa bir göyərtə quruluşu, uçuş ...</td>\n",
       "      <td>Xizəklə tullanma rampasını ilk olaraq kim inki...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'answer_start': [283], 'text': ['kral donanma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9872 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id                             title  \\\n",
       "0     5727746d708984140094de08                       Switzerland   \n",
       "1     571098c9a58dae1900cd6aaa              Age_of_Enlightenment   \n",
       "2     56cef84faab44d1400b88d56                     New_York_City   \n",
       "3     57315c6c497a881900248e82                            Mosaic   \n",
       "4     570d4d9efed7b91900d45e50                          Valencia   \n",
       "...                        ...                               ...   \n",
       "9867  56bfb8dca10cfb140055127b                           Beyoncé   \n",
       "9868  57301e6bb2c2fd14005688bd                    Roman_Republic   \n",
       "9869  56db76b7e7c41114004b5154  2008_Summer_Olympics_torch_relay   \n",
       "9870  5728cdc64b864d1900164e75                           Detroit   \n",
       "9871  570aae5d4103511400d59920                  Aircraft_carrier   \n",
       "\n",
       "                                                context  \\\n",
       "0     1200-cü ilə qədər İsveçrə yaylası Savoy, Zähri...   \n",
       "1     Qəhvəxanalar Maarifçilik dövründə biliyin yayı...   \n",
       "2     Şəhərin ümumi sahəsi 468,9 kvadrat mil (1,214 ...   \n",
       "3     Konstantin Monomaxosun digər böyük işi 1042-10...   \n",
       "4     15-ci əsrdə günbəz əlavə edildi və neflər xoru...   \n",
       "...                                                 ...   \n",
       "9867  O, Destiny's Child ilə yazılan mahnıların əksə...   \n",
       "9868  Klodius şəhəri dəhşətə gətirən silahlı dəstələ...   \n",
       "9869  Xinhua və CCTV, əksər Qərb mediasından daha ço...   \n",
       "9870  Bölgənin bir çox görkəmli muzeyləri Ueyn Dövlə...   \n",
       "9871  Görülə bilən başqa bir göyərtə quruluşu, uçuş ...   \n",
       "\n",
       "                                               question  is_impossible  \\\n",
       "0     1264-cü ildə Kiburq sülaləsinin süqutuna səbəb...          False   \n",
       "1     Hansı məkan müxtəlif təbəqələrdən olan insanla...          False   \n",
       "2            Nyu Yorkun ən hündür nöqtəsinin adı nədir?          False   \n",
       "3     Rus abbat Daniel 1106-07-ci illərdə hara səyah...          False   \n",
       "4                  Həvarilərin qapısı hansı üslubdadır?          False   \n",
       "...                                                 ...            ...   \n",
       "9867           Jay Z ilə onun yeni mövzuları nələr idi?          False   \n",
       "9868  Pompey ardıcıllarına edilən hücumlara kim cava...          False   \n",
       "9869  Hansı nəşr etirazçıların insan haqlarını tapda...          False   \n",
       "9870                                 MOCAD nə deməkdir?          False   \n",
       "9871  Xizəklə tullanma rampasını ilk olaraq kim inki...          False   \n",
       "\n",
       "                                                answers  \n",
       "0     {'answer_start': [294], 'text': ['1263-cü ildə...  \n",
       "1       {'answer_start': [0], 'text': ['Qəhvəxanalar']}  \n",
       "2        {'answer_start': [175], 'text': ['Todt Hill']}  \n",
       "3        {'answer_start': [270], 'text': ['Yerusəlim']}  \n",
       "4           {'answer_start': [411], 'text': ['Qotika']}  \n",
       "...                                                 ...  \n",
       "9867  {'answer_start': [309], 'text': ['insana qullu...  \n",
       "9868         {'answer_start': [0], 'text': ['Clodius']}  \n",
       "9869        {'answer_start': [592], 'text': ['Sinxua']}  \n",
       "9870  {'answer_start': [171], 'text': ['Detroit Müas...  \n",
       "9871  {'answer_start': [283], 'text': ['kral donanma...  \n",
       "\n",
       "[9872 rows x 6 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train = df_train[:10000].sample(frac=1, random_state=42)\n",
    "\n",
    "\n",
    "df_train = train[:-64].reset_index(drop=True)\n",
    "df_valid = train[-64:].reset_index(drop=True)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(df_train)\n",
    "valid_dataset = Dataset.from_pandas(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '56e758c700c9c71400d76fe5',\n",
       " 'title': 'Paper',\n",
       " 'context': 'Vərəqə basaraq suyu güclə çıxarır; su təbəqədən zorla çəkildikdən sonra suyu toplamaq üçün ənənəvi ilə qarışdırılmayan xüsusi növ keçə istifadə olunur; halbuki əl ilə kağız hazırlayarkən onun yerinə qurutma vərəqi istifadə olunur.',\n",
       " 'question': 'Presdən xaric olan suyu toplamaq üçün nə istifadə olunur?',\n",
       " 'is_impossible': False,\n",
       " 'answers': {'answer_start': [106], 'text': ['hiss etdi']}}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]['context'][445:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Map: 100%|██████████| 9808/9808 [00:02<00:00, 4875.22 examples/s]\n",
      "\n",
      "Map: 100%|██████████| 64/64 [00:00<00:00, 4102.07 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_train_ds = train_dataset.map(prepare_train_features, batched=True, remove_columns=train_dataset.column_names)\n",
    "tokenized_valid_ds = valid_dataset.map(prepare_train_features, batched=True, remove_columns=train_dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "    num_rows: 64\n",
       "})"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"finetune-BERT-squad\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('mps')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch is built with MPS support\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_built():\n",
    "    print(\"PyTorch is built with MPS support\")\n",
    "else:\n",
    "    print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "data_collator = DefaultDataCollator()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_train_ds,\n",
    "    eval_dataset=tokenized_valid_ds,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 13.69 GB, other allocations: 4.23 GB, max allowed: 18.13 GB). Tried to allocate 512.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[158], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/Desktop/assigmnt_final/SQuAD_Azerbaijan/.venv/lib/python3.10/site-packages/transformers/trainer.py:1780\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1778\u001b[0m         hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1779\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1780\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1781\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1782\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1783\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1784\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1785\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/assigmnt_final/SQuAD_Azerbaijan/.venv/lib/python3.10/site-packages/transformers/trainer.py:2118\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2115\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_begin(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[1;32m   2117\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2118\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   2120\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   2121\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2122\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2123\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2124\u001b[0m ):\n\u001b[1;32m   2125\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2126\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/Desktop/assigmnt_final/SQuAD_Azerbaijan/.venv/lib/python3.10/site-packages/transformers/trainer.py:3036\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3033\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m   3035\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3036\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs)\n\u001b[1;32m   3038\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mn_gpu \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3039\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()  \u001b[39m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/assigmnt_final/SQuAD_Azerbaijan/.venv/lib/python3.10/site-packages/transformers/trainer.py:3059\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3057\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3058\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 3059\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m   3060\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3061\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3062\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/assigmnt_final/SQuAD_Azerbaijan/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/assigmnt_final/SQuAD_Azerbaijan/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/assigmnt_final/SQuAD_Azerbaijan/.venv/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:1516\u001b[0m, in \u001b[0;36mXLMRobertaForQuestionAnswering.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, start_positions, end_positions, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1504\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[39mstart_positions (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m \u001b[39m    Labels for position (index) of the start of the labelled span for computing the token classification loss.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1512\u001b[0m \u001b[39m    are not taken into account for computing the loss.\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1516\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroberta(\n\u001b[1;32m   1517\u001b[0m     input_ids,\n\u001b[1;32m   1518\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1519\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1520\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1521\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1522\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1523\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1524\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1525\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1526\u001b[0m )\n\u001b[1;32m   1528\u001b[0m sequence_output \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1530\u001b[0m logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mqa_outputs(sequence_output)\n",
      "File \u001b[0;32m~/Desktop/assigmnt_final/SQuAD_Azerbaijan/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/assigmnt_final/SQuAD_Azerbaijan/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/assigmnt_final/SQuAD_Azerbaijan/.venv/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:837\u001b[0m, in \u001b[0;36mXLMRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    828\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    830\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m    831\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m    832\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    835\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    836\u001b[0m )\n\u001b[0;32m--> 837\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    838\u001b[0m     embedding_output,\n\u001b[1;32m    839\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m    840\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    841\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    842\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m    843\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m    844\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    845\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    846\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    847\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    848\u001b[0m )\n\u001b[1;32m    849\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    850\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/assigmnt_final/SQuAD_Azerbaijan/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/assigmnt_final/SQuAD_Azerbaijan/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/assigmnt_final/SQuAD_Azerbaijan/.venv/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:525\u001b[0m, in \u001b[0;36mXLMRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    514\u001b[0m     layer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    515\u001b[0m         layer_module\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m,\n\u001b[1;32m    516\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    522\u001b[0m         output_attentions,\n\u001b[1;32m    523\u001b[0m     )\n\u001b[1;32m    524\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 525\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    526\u001b[0m         hidden_states,\n\u001b[1;32m    527\u001b[0m         attention_mask,\n\u001b[1;32m    528\u001b[0m         layer_head_mask,\n\u001b[1;32m    529\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    530\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    531\u001b[0m         past_key_value,\n\u001b[1;32m    532\u001b[0m         output_attentions,\n\u001b[1;32m    533\u001b[0m     )\n\u001b[1;32m    535\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    536\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/Desktop/assigmnt_final/SQuAD_Azerbaijan/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/assigmnt_final/SQuAD_Azerbaijan/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/assigmnt_final/SQuAD_Azerbaijan/.venv/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:414\u001b[0m, in \u001b[0;36mXLMRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    403\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    404\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    411\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m    412\u001b[0m     \u001b[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    413\u001b[0m     self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 414\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    415\u001b[0m         hidden_states,\n\u001b[1;32m    416\u001b[0m         attention_mask,\n\u001b[1;32m    417\u001b[0m         head_mask,\n\u001b[1;32m    418\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    419\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[1;32m    420\u001b[0m     )\n\u001b[1;32m    421\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    423\u001b[0m     \u001b[39m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/assigmnt_final/SQuAD_Azerbaijan/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/assigmnt_final/SQuAD_Azerbaijan/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/assigmnt_final/SQuAD_Azerbaijan/.venv/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:341\u001b[0m, in \u001b[0;36mXLMRobertaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    332\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    333\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    339\u001b[0m     output_attentions: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    340\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m--> 341\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself(\n\u001b[1;32m    342\u001b[0m         hidden_states,\n\u001b[1;32m    343\u001b[0m         attention_mask,\n\u001b[1;32m    344\u001b[0m         head_mask,\n\u001b[1;32m    345\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    346\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    347\u001b[0m         past_key_value,\n\u001b[1;32m    348\u001b[0m         output_attentions,\n\u001b[1;32m    349\u001b[0m     )\n\u001b[1;32m    350\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(self_outputs[\u001b[39m0\u001b[39m], hidden_states)\n\u001b[1;32m    351\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/assigmnt_final/SQuAD_Azerbaijan/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/assigmnt_final/SQuAD_Azerbaijan/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/assigmnt_final/SQuAD_Azerbaijan/.venv/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:261\u001b[0m, in \u001b[0;36mXLMRobertaSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    258\u001b[0m         relative_position_scores_key \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39meinsum(\u001b[39m\"\u001b[39m\u001b[39mbhrd,lrd->bhlr\u001b[39m\u001b[39m\"\u001b[39m, key_layer, positional_embedding)\n\u001b[1;32m    259\u001b[0m         attention_scores \u001b[39m=\u001b[39m attention_scores \u001b[39m+\u001b[39m relative_position_scores_query \u001b[39m+\u001b[39m relative_position_scores_key\n\u001b[0;32m--> 261\u001b[0m attention_scores \u001b[39m=\u001b[39m attention_scores \u001b[39m/\u001b[39;49m math\u001b[39m.\u001b[39;49msqrt(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention_head_size)\n\u001b[1;32m    262\u001b[0m \u001b[39mif\u001b[39;00m attention_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    263\u001b[0m     \u001b[39m# Apply the attention mask is (precomputed for all layers in XLMRobertaModel forward() function)\u001b[39;00m\n\u001b[1;32m    264\u001b[0m     attention_scores \u001b[39m=\u001b[39m attention_scores \u001b[39m+\u001b[39m attention_mask\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 13.69 GB, other allocations: 4.23 GB, max allowed: 18.13 GB). Tried to allocate 512.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
